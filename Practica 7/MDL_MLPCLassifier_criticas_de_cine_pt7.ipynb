{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7c6418",
   "metadata": {},
   "source": [
    "## Universidad Autonoma de Aguascalientes\n",
    "## Departamento: Ciencias de la computacion\n",
    "## Carrera: Ingenieria en Computacion Inteligente\n",
    "## Curso: Machine y Deep Learning\n",
    "## Maestro: Dr. Francisco Javier Luna Rosas\n",
    "## Alumno: Guillermo González Lara (237864)\n",
    "## Semestre: Enero_Junio del 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba46f79",
   "metadata": {},
   "source": [
    "# Práctica No. 7: Análisis de Sentimientos con Redes Neuronales (MLPClassifier)\n",
    "\n",
    "## Objetivo\n",
    "En esta práctica implementaremos un modelo de análisis de sentimientos utilizando el algoritmo de **Perceptrón Multicapa (MLP)** de la librería Scikit-Learn. \n",
    "\n",
    "El objetivo es clasificar críticas de cine del dataset `movie_data.csv` en dos categorías:\n",
    "* **Positiva (1)**\n",
    "* **Negativa (0)**\n",
    "\n",
    "Dado que las redes neuronales requieren entradas numéricas, utilizaremos técnicas de procesamiento de lenguaje natural (NLP) como la **Bolsa de Palabras (Bag of Words)** para transformar el texto de las críticas en vectores numéricos antes de entrenar la red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33b1979",
   "metadata": {},
   "source": [
    "### Paso 1: Importar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14452ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Para mostrar todas las columnas si fuera necesario\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147394c8",
   "metadata": {},
   "source": [
    "### Paso 2: Cargar el dataset\n",
    "Cargamos el archivo `movie_data.csv` que se encuentra en la carpeta raíz. Este dataset contiene dos columnas principales: `review` (el texto de la crítica) y `sentiment` (la etiqueta: 0 o 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87cecbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson and his usual easy going delivery of lines in his m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think about watching that movie, although it would be a w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonderful movie im sure thet you would have liked it as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how much I hated the movie version of \"A Chorus Line....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                review  \\\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, ...   \n",
       "1  OK... so... I really like Kris Kristofferson and his usual easy going delivery of lines in his m...   \n",
       "2  ***SPOILER*** Do not read this, if you think about watching that movie, although it would be a w...   \n",
       "3  hi for all the people who have seen this wonderful movie im sure thet you would have liked it as...   \n",
       "4  I recently bought the DVD, forgetting just how much I hated the movie version of \"A Chorus Line....   \n",
       "\n",
       "   sentiment  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de etiquetas:\n",
      "sentiment\n",
      "1    25000\n",
      "0    25000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Carga del dataset asumiendo que está en la raíz\n",
    "df = pd.read_csv('../movie_data.csv')\n",
    "\n",
    "# Mostrar las primeras 5 filas para verificar la estructura\n",
    "print(\"Primeras filas del dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Verificar la distribución de clases (cuántas positivas y negativas hay)\n",
    "print(\"\\nDistribución de etiquetas:\")\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708296f2",
   "metadata": {},
   "source": [
    "### Paso 3: Preprocesamiento y Vectorización de Texto\n",
    "Las redes neuronales no pueden procesar texto crudo directamente. Necesitamos convertir las oraciones en números.\n",
    "\n",
    "Utilizaremos `CountVectorizer` para crear una \"Bolsa de Palabras\". Esto convertirá cada crítica en un vector que cuenta la frecuencia de cada palabra.\n",
    "* **stop_words='english'**: Eliminaremos palabras comunes en inglés (como \"the\", \"is\", \"at\") que no aportan mucho significado.\n",
    "* **max_features=2000**: Limitaremos el vocabulario a las 2000 palabras más frecuentes para evitar que la red neuronal sea demasiado pesada y lenta para este ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23756f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión de la matriz de características (X): (50000, 2000)\n",
      "Ejemplo: Las críticas ahora son representaciones numéricas dispersas.\n"
     ]
    }
   ],
   "source": [
    "# Definimos las variables de entrada (X) y salida (y)\n",
    "X_texto = df['review']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Instanciamos el vectorizador\n",
    "# Limitamos a 2000 palabras para agilizar el cómputo en esta práctica\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=2000)\n",
    "\n",
    "# Transformamos el texto a números\n",
    "X = vectorizer.fit_transform(X_texto)\n",
    "\n",
    "print(f\"Dimensión de la matriz de características (X): {X.shape}\")\n",
    "print(\"Ejemplo: Las críticas ahora son representaciones numéricas dispersas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e5ea1c",
   "metadata": {},
   "source": [
    "### Paso 4: División de datos en entrenamiento y prueba\n",
    "Separamos los datos en dos conjuntos: 70% para entrenar la red neuronal y 30% para evaluar su desempeño con datos no vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6666f0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de entrenamiento: (35000, 2000)\n",
      "Datos de prueba: (15000, 2000)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Datos de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Datos de prueba: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdf8a94",
   "metadata": {},
   "source": [
    "### Paso 5: Implementación y Entrenamiento del MLPClassifier\n",
    "Configuramos la red neuronal. Usaremos:\n",
    "* **hidden_layer_sizes=(100, 50)**: Dos capas ocultas, la primera con 100 neuronas y la segunda con 50.\n",
    "* **activation='relu'**: Función de activación estándar para capas ocultas.\n",
    "* **max_iter=500**: Aumentamos las iteraciones máximas para asegurar que el modelo converja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfc20887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.37922949\n",
      "Iteration 2, loss = 0.26496224\n",
      "Iteration 3, loss = 0.21221447\n",
      "Iteration 4, loss = 0.13986347\n",
      "Iteration 5, loss = 0.07186221\n",
      "Iteration 6, loss = 0.02966865\n",
      "Iteration 7, loss = 0.01082870\n",
      "Iteration 8, loss = 0.00401549\n",
      "Iteration 9, loss = 0.00191267\n",
      "Iteration 10, loss = 0.00123783\n",
      "Iteration 11, loss = 0.00083624\n",
      "Iteration 12, loss = 0.00059205\n",
      "Iteration 13, loss = 0.00048593\n",
      "Iteration 14, loss = 0.00041904\n",
      "Iteration 15, loss = 0.00037181\n",
      "Iteration 16, loss = 0.00033703\n",
      "Iteration 17, loss = 0.00031078\n",
      "Iteration 18, loss = 0.00029069\n",
      "Iteration 19, loss = 0.00027483\n",
      "Iteration 20, loss = 0.00026209\n",
      "Iteration 21, loss = 0.00025183\n",
      "Iteration 22, loss = 0.00024345\n",
      "Iteration 23, loss = 0.00023648\n",
      "Iteration 24, loss = 0.00023069\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "Entrenamiento finalizado.\n"
     ]
    }
   ],
   "source": [
    "# Instanciar el clasificador MLP\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), \n",
    "                    activation='relu', \n",
    "                    solver='adam', \n",
    "                    max_iter=500, \n",
    "                    random_state=42,\n",
    "                    verbose=True) # verbose=True para ver el progreso del entrenamiento\n",
    "\n",
    "# Entrenar el modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nEntrenamiento finalizado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecec31a",
   "metadata": {},
   "source": [
    "### Paso 6: Evaluación del Modelo\n",
    "Realizamos predicciones sobre el conjunto de prueba (`X_test`) y evaluamos la precisión utilizando la matriz de confusión y el reporte de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2f875f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[6366 1130]\n",
      " [1015 6489]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86      7496\n",
      "           1       0.85      0.86      0.86      7504\n",
      "\n",
      "    accuracy                           0.86     15000\n",
      "   macro avg       0.86      0.86      0.86     15000\n",
      "weighted avg       0.86      0.86      0.86     15000\n",
      "\n",
      "Precisión del modelo: 0.8570\n"
     ]
    }
   ],
   "source": [
    "# Predicción\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Matriz de Confusión\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Reporte de Clasificación\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Precisión Global\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a414a",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En esta práctica número 7, aplicamos una red neuronal de tipo Perceptrón Multicapa (MLP) para una tarea de Procesamiento de Lenguaje Natural (NLP). Logramos transformar texto no estructurado (críticas de cine) en datos numéricos utilizando `CountVectorizer`.\n",
    "\n",
    "El modelo fue capaz de aprender patrones en las palabras asociadas a críticas positivas y negativas. A pesar de limitar el vocabulario a 2000 palabras por razones de eficiencia, el `MLPClassifier` demostró ser una herramienta robusta para problemas de clasificación binaria con datos de alta dimensionalidad.\n",
    "\n",
    "### Referencias\n",
    "* Scikit-learn: Machine Learning in Python. URL: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "* Pang, B., & Lee, L. (2004). A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. (Dataset source)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
